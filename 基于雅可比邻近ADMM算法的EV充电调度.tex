\documentclass[a4paper,10pt]{article}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{color}
\usepackage{esint,graphicx}
\usepackage{diagbox}
\usepackage{graphics}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{CJK}%中文
\usepackage{algorithm}
\usepackage{algorithmic}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}{Example}[section]
\newtheorem{xca}[theorem]{Exercise}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}{Remark}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{condition}{Condition}[section]
\newtheorem{proposition}{Proposition}[section]
\numberwithin{equation}{section}

\renewcommand{\d}{{\rm d}}
\newcommand{\Caputo}{{\mathcal{D}^\alpha_t}}
\newcommand{\DCaputo}{{\mathcal{D}^\alpha_\tau}}
\newcommand{\Ank}{{A_{n-k}^{(n)}}}
\newcommand{\rd}[1]{{\color{red}#1}}
\newcommand{\bl}[1]{{\color{blue}#1}}


\usepackage{subfig,graphicx}
\begin{document}
\begin{CJK*}{GBK}{song}

\title{基于JPADMM~EV 充电调度}
\maketitle
%\section{问题描述}
%
%在这种模式下,~电动汽车用户将电动汽车连接到充电桩,~充电需求信息上传到聚合器.~每个电动汽车的充电计划将被发送回给电动汽车用户，充电信息包括到达时间~$t_i^a$,
%
%在所提的模型中的一些假设,~首先，电动汽车用户对充电成本很敏感,~ 我们引入有序充电的策略,~对于一些不着急充电的用户来说可以选择在电价低时期进行充电,~电价高时不来充电,~从而达到削峰填谷的效果,~ 第二,~我们假设电动汽车用户的到达时间和离开时间服从以下的泊松分布:
\section{研究现状}
文献[1]提出了一个促进稀疏性的充电控制模型。在该模型中，通过优化充电时段的数量，提高用户的满意度。模型中引入了动态馈线过载约束，以避免出现不可接受的负荷峰值，从而保证网络的稳定性。然后，针对大多数电网典型的分布式管理方式，提出了一种基于~$ADMM$~的分布式解决策略。在求解过程中，利用拉格朗日对偶将原问题转化为等价对偶问题，该对偶问题可分解为一组齐次的小尺度子问题。具体地说，每个子问题要么有一个闭解，要么可以用加速对偶梯度法局部求解。并证明了算法的全局收敛性。文献[2]创新性地将电动汽车快速充电问题建模为配电网中受耦合馈线容量约束的优化协调问题。快速充电的需求用总充电时间和在期望时间内充满电的相对趋势来表示。我们引入一个非凸的充电策略的0-范数来表示总充电时间，并应用1-范数最小化来近似0- 范数最小化的稀疏解。充电周期越短，用户的快速充电意愿越强。优化问题的目标是权衡电动汽车电池退化成本、配电网负荷调节、充电满意度和总充电时间，而充电时间在单个充电行为中是不可分的。尽管~$ADMM$~在目标可分、约束耦合的分布式优化中得到了广泛的应用，但其分散方案不能直接应用于潜在的不可分电动汽车充电协调问题。为此，提出了一种基于~$ADMM$~的分层算法，保证在一定步长参数下收敛到最优策略。基于以上两篇文献，本文创新地将从用户角度出发，将充电成本、用户满意度以及充电时间建模为协调优化方法，
\section{本文主要贡献}

首先我们提出了一种新的分布式雅可比近端交替方向乘子算法来解决大规模电动汽车充电调度问题,\,该算法可以并行更新变量,

1)本文创新地将电动汽车充电优化建模与经济优化调度相关的问题，将充电总成本、峰谷负荷、用户满意度、

2）设计了一种新的基于分布式\,$Jacobi-Proximal\,\,ADMM$\,的算法来解决具有时间空间耦合不等式约束的不可分优化问题,\,并从理论上证明了该算法的最优性和收敛性,\,从理论和数值实验上证明了与经典的~$ADMM$~相比收敛速度快.\,保护每位电动汽车车主的隐私.

\section{电动汽车充电模型}
引入记号:
设~$\bm{p}\in \mathbb{R}^n$,\,$\|\bm{p}\|_2=(\sum_{i=1}^np_i^2)^{1/2}$\,表示标准的欧式范数,\,$\|\bm{p}\|_0=\sharp(i|p_i\neq0)$\,表示向量\,$\bm{p}$\,中非零元的个数.矩阵\,$\bm{A}$\,的\,$Frobenius$\,范数表示为\,$\|\bm{A}\|_F=(\sum_{i=1}^n\sum_{j=1}^na_{ij}^2)^{1/2}$.\,\\

\begin{table}[htbp]
	\centering
	\caption{符号表示}
	\label{tab:1}
	\begin{tabular}{cccc ccc}%表格中的数据居中，c的个数为表格的列数
		\hline\hline\noalign{\smallskip}	
		$\mathcal{N}$&电动汽车个数集合:$\mathcal{N}=\{1,...,N\}$ \\
		%\noalign{\smallskip}\hline\noalign{\smallskip}
		$\mathcal{T}$&离散时间集合:$\mathcal{T}=\{1,...,T\}$ \\
		$\mathcal{L}$&馈线集合:$\mathcal{L}=\{1,...,L\}$ \\
        $p_{n,t}$&在\,$t$\,时刻第\,$n$\,辆电动汽车的充电速率\\
        $\mathcal{N}_l$&通过馈线\,$l$\,供电的电动汽车的集合\\
        $\mathcal{N}_m$&在节点\,$m$\,充电的电动汽车的集合\\
        $C_n$&电动汽车的电车容量\\
        $d_t$&在\,$t$\,时刻总基本需求\\

		\noalign{\smallskip}\hline
	\end{tabular}
\end{table}

在本节中建立一个协调调度充电模型来控制电动汽车充电,\,令\,$\bm{p}_n=(p_{n,1},...,p_{n,T})\in\mathbb{R}^T$,\,$\bm{p}=(\bm{p}_1,...,\bm{p}_N).$\\
\subsection{EV充电约束}
基于分段线性模型[1],\,电池动态描述如下:
\begin{align}
SOC_{n,t+1}=SOC_{n,t}+\frac{p_{n,t}\times\bigtriangleup t\times \eta_n^+}{C_n}
\end{align}
\begin{align}
SOC_n^{min}\leq SOC_{n,t}\leq SOC_n^{max},
\end{align}

其中\,$\eta_n^+,\eta_n^-\in(0,1]$\,各自代表充放电能量转换效率.\,为了延长电池寿命,\,建议\,$SOC^{min}$\,和\,$SOC^{max}$\,分别为\,$15\%$\, 和\,$90\%$[2].
\begin{align}\label{SOCC}
\frac{C_n}{\eta_n^+ \Delta t}&(SOC_n^{min}-SOC_n^{init})\leq \sum_{t=1}^T p_{n,t}
 \leq \frac{C_n}{\eta_n^+\Delta t}(SOC_n^{max}-S_n^{init})
\end{align}
其中\,$SOC^{init}$\,是\,$EV~n$\,的初始\,$SOC$\,值.设\,$p_n^{min}$\, 和\,$p_n^{max}$\,分别为\,$EV n$\,的最小和最大功率,\,我们有以下不等式约束:
\begin{align}
p_n^{min}\leq p_{n,t}\leq p_{n}^{max},\,\,n\in \mathcal{N},\,\,t\in \mathcal{T},
\end{align}
通过决定电动汽车在每个时隙中是否充电,\,实现了电动汽车的协调充电调度,\,第\,$n$\,个\,$EV$\,充电状态如下:
\begin{align}
X_{n,t}=\left\{
\begin{array}{cl}
1 & \text{如果电动汽车在充电,}\\
0 & \text{其它}.\\
\end{array}\right.
\end{align}
约束满足以下形式:
\begin{align}
(1-X_{n,t})p_{n,t}=0,~n\in \mathcal{N},~t\in \mathcal{T}
\end{align}
在实践中,\,一般采用以下保守约束,\,即每个\,$EV\,n$\,在有限时间范围\,$T$\,结束时至少达到最终\,$SOC$\,值,\,表示为\,$SOC_n^{final}$,
\begin{align}\label{powerC}
\sum_{t=1}^Tp_{n,t}\geq \frac{C_n}{q_n^+\Delta t}(SOC_n^{final}-SOC_n^{init}).
\end{align}
为了简化表示,~定义~$\mathcal{P}_n^{(1)}$~如下
\begin{align}
\mathcal{P}_n^{(1)}=\{\bm{p}_n|\bm{p}_n\,\,\text{满足}(\ref{SOCC})-(\ref{powerC})\}
\end{align}
%设~$\mathbf{P}\triangleq (\mathbf{P}_n;n\in \mathcal{N})$~表示电动汽车的充电策略,~第~$n$~辆电动汽车的容许充电策略集用~$\mathcal{P}_n$~表示,~所有电动汽车的容许充电策略集用~$\mathcal{P}$~表示
设
 \begin{align}
 \mathcal{P}^{(1)}\triangleq \mathcal{P}_1^{(1)} \times \mathcal{P}_2^{(1)}\cdot\cdot\cdot \times \mathcal{P}_N^{(1)}
 \end{align}

{\color{red}\subsection{馈线容量约束}}
 对于分布式电网:\,我们分别用\,$\mathcal{L}\equiv\{1,...,L\}$\,和\,$\mathcal{M}\equiv\{1,...,M\}$\,分别表示馈线和节点集合,\,用\,$\mathcal{N}_l,\,l\in \mathcal{L}$\,表示通过馈线\,$l$\,供电的电动汽车的集合,\,$\mathcal{N}_m,\,m\in \mathcal{M}$\,表示通过根节点\,$m$\, 处供电的电动汽车的集合.\,定义连接在节点\,$m$\,的基本需求表示为\,$d_m=(d_{mt},\,t\in\mathcal{L})$,\,通过馈线\,$l$\,的总的基本需求\,$D_{lt}\equiv \sum_{m\in\mathcal{M}_l}d_{mt}$,\,其中\,$\mathcal{M}_l$\,表示通过馈线\,$l$\,的节点集合,\,其功率通过馈线\,$l$\, 进行分配\,$\mathbf{d}=(d_t,t\in\mathcal{T})$\,表示配电网的总基本需求\,$\mathcal{M}_l$,\,则配电网中所有馈线在充电期间的功率容量可表示为电动汽车的充电策略应满足馈线容量的约束:
\begin{align*}
c_{l,t}=\beta_l-D_{lt},\\
\end{align*}
且
\begin{align}
\sum_{n\in\Pi_n}p_{n,t}\leq c_{lt}.
\end{align}
\subsection{目标函数}
\begin{align}
\mathcal{J}_0(\bm{p})&\triangleq\sum_{n\in \mathcal{N}}\left\{f_n(p_{nt})
+g_n(\sum_{t\in\mathcal{N}}p_{nt})
+\|\bm{p}_n\|_0\right\}
+\sum_{t\in \mathcal{T}}h_n(\sum_{t\in\mathcal{T}}p_{nt})
\end{align}

每一项的具体解释如下:

1) 第一项~$f_n(p_{nt})$:~它代表第~$n$~辆电动汽车的充电总成本,如文献[1]所示,~$f_n(p_{nt})$~ 的具体表达式:
\begin{align*}
f_n(p_{nt})=\sum_{t\in \mathcal{T}}E_tp_{nt}\Delta t
\end{align*}
其中,~$E_t$~为~$t$~时间段的电价,~$p_{nt}$~为电动汽车~$t$~时间段的充电功率,~$\Delta t$~为时间间隔.

2) 第二项$g_n(\sum_{t\in \mathcal{T}}p_{nt})$:\,它是关于在充电期间交付的总能量的满意函数,\,电动汽车用户更愿意充电时,\,直到他们在所需的时间内达到所需的容量\,$\Gamma_n$,\,然后,\,我们提出以下形式表示用户的满意度:
\begin{align*}
g_n(\sum_{t\in \mathcal{T}}p_{nt})=-(\sum_{t\in \mathcal{T}}p_{nt}-\Gamma_n)^2.
\end{align*}


3)第三项\,$\|\bm{p}_n\|$:\,基数最小化\,$\|\bm{p}_n\|_0$\,在稀疏解的建模中起着重要作用,\,然而\,$\|\bm{p}_n\|_0$\,的计算仍然是一个挑战,\,因为\,$\|\bm{p}_n\|_0$\,是一个非凸函数,\,直接优化这个函数甚至在线性约束上被证明是一个\,$NP$\,困难问题.\,无法通过常规方法求解最小\,$\|\bm{p}_n\|_0$\, 问题和最小\,$\|\bm{p}_n\|_1$\,范数问题在一定条件下是等价的,\,即可以通过求解最小\,$\|\bm{p}_n\|_1$\,问题来得到最小\,$\|\bm{p}_n\|_0$\, 问题的解.\,求解最小\,$\|\bm{p}_n\|_1$\,问题因为是凸优化问题相对来说简单得多.

4) 第四项\,$h_n(\sum_{t\in\mathcal{T}}p_{nt})$:\,表示负荷调节,\,也表示配电网对总电力需求的功率损耗,\,$\delta_n$\,为加权参数,\,反应了快速充电行为对电网的影响趋势,\,其中\,$\overline{\mathbf{p}}$\,表示平均功率,\,具体表示为\,$\overline{\mathbf{p}}=\frac{1}{N}\mathop{\sum}\limits_{n\in \mathcal{N}}\mathop{\sum}\limits_{t\in \mathcal{T}}p_{nt}$\\

插入\,$l_1$\,凸逼近,\,我们将\,$(2.1)$\,重新建模为以下稀疏促进充电控制模型
\begin{align}\label{OBJ}
\mathcal{J}(\bm{p})\triangleq \sum_{n \in \mathcal{N}}\left\{f_n(p_{nt})-\omega_ng_n(\sum_{t\in \mathcal{T}}p_{nt})+\gamma\|\bm{p}_n\|_1\right\}+\delta_n\sum_{t\in \mathcal{T}}h_n(\sum_{t\in\mathcal{T}}p_{nt})\\\nonumber
\end{align}
\section{雅可比邻近ADMM求解模型}

ADMM方法已经成为大规模结构化的有力工具,\,值得注意的是,\,$ADMM$~可以解耦空间耦合约束,\,并将解耦问题分解为许多个小问题,\,其中每个子问题分解都很容易解决.\,在\,[1]\,中提出了并行分布式计算\,$Jacobi-Proximal\, ADMM$.\,近端项的灵活使用以不同的方法解决子问题\,提高了标准\,$ADMM$\, 的收敛率.
值得注意的是,\,在模型\,(11)\,中的第二项耦合了所有的变量\,$p_{n,t},\,n\in \mathcal{N}$,\,为了解耦此项,\,引入辅助变量
\begin{align*}
\bm{p}_{N+1}=(p_{N+1,1},\cdot\cdot\cdot,p_{N+1,1})^T\in \mathbb{R}^T
\end{align*}
其中~$p_{N+1,t}=\sum\limits_{t\in \mathcal{T}}p_{nt}-\Gamma_n,t\in \mathcal{T}$,\,因此模型(\ref{OBJ})等价表示如下:
\begin{align}
&\min_{\bm{p}}\,\,\,\mathcal{J}(\bm{p})\label{objectf}\\
&\,\,s.t.\,\,\,\sum_{n\in\mathcal{M}_l}p_{n,t}\leq c_{lt}\label{objectfc1}\\
&\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,p_{N+1,t}=\sum\limits_{t\in \mathcal{T}}p_{nt}-\overline{\bm{p}},\,t\in \mathcal{T}\label{objectfc2}
\end{align}

为了使用\,$Jacobi-Proximal\,\,ADMM$\,,定义
\begin{align}
\bm{P}=\{\bm{p}_1,...,\bm{p}_N,\bm{p}_{N+1}\}^{T}\in\mathcal{R}^{(N+1)\times T}
\end{align}

也可以写成\,$\bm{P}=(\bm{p}_1,...,\bm{p}_T)\in\mathbb{R}^{(N+1)\times T}$,\, 其中
\begin{align}
\bm{p}_t=(p_{1,t},...,p_{N+1,t})\in \mathbb{R}^{N+1},\,t\in\mathcal{T}.
\end{align}
定义
\begin{align}
\mathcal{P}_t^{(2)}=\{\bm{p}_t|\bm{p}_t\,\,\text{满足}\,(\ref{objectfc1})~and~(\ref{objectfc2})\}
\end{align}
且
\begin{align}
\mathcal{P}_t^{(2)}=\mathcal{P}_1^{(2)}\times \cdot\cdot\cdot \times \mathcal{P}_t^{(2)}\times\cdot\cdot\cdot\times \mathcal{P}_T^{(2)}
\end{align}
其中约束\,$P_t^{(2)}$\,是一个全局约束,\,在空间上耦合所有EV的充电时间表.\,$P_t^{(2)}$\,是闭的、非空凸集的指示函数是恰当的、闭的和凸的,\,所以为了使用\,$Jacobi-Proximal\,ADMM$\,更一步介绍以下凸集\,$P^{(i)},i=1,2$,\, 如下，
\begin{equation}
\mathcal{I}_i(\bm{p})=\left\{
\begin{array}{cl}
0 & if\quad \bm{p} \in \mathcal{P}^{(i)},\\
+\infty & otherwise.\\
\end{array}\right.
\end{equation}
很清楚地,\,$\mathcal{I}_i(\bm{p}),\,i=1,2$\,是凸函数.

很容易地将~$(\ref{objectf})-(\ref{objectfc2})$~所描述的问题写成标准的ADMM 形式，如下所示
\begin{align}
&\min_{\bm{P},\bm{Y}}\mathcal{J}(\bm{P})+\mathcal{I}_1(\bm{P})+\mathcal{I}_2(\bm{Y})\\
&s.t~~\bm{P}-\bm{Y}=0.\nonumber
\end{align}
这里定义:
\begin{align*}
&F(\bm{P})\triangleq \mathcal{J}(\bm{P})+\mathcal{I}_1(\bm{P})\\
&G(\bm{Y})\triangleq \mathcal{I}_2(\bm{Y})
\end{align*}

定义增广拉格朗日函数如下:
\begin{align}
\mathcal{L}_{\rho}(\bm{P},\bm{Y},\bm{U})&=F(\bm{P})+G(\bm{Y})+\Lambda^T(\bm{P}-\bm{Y})+\frac{\rho}{2}\|\bm{P}-\bm{Y}\|_F^2\\
&=f(\bm{P})+g(\bm{Y})+\frac{\rho}{2}\|\bm{P}-\bm{Y}+\bm{U}\|_F^2\nonumber
\end{align}
其中~$\rho>0$~是惩罚参数,\,$\Lambda$\,称为对偶变量或者拉格朗日乘子,\,$\bm{U}$称为缩放后的对偶变量,\,i.e.$\bm{U}=(1/\rho)\Lambda$\,变量\,$\bm{P},\bm{Y},\bm{U}$\,的更新

\begin{align}
&\bm{P}^{k+1} \triangleq \mathop{argmin}\limits_{\bm{P}}\left\{\mathcal{L}_{\rho}(\bm{P},\bm{Y},\bm{U}^k)+\frac{1}{2}\|\bm{P}-\bm{P}^k\|_{\Phi}^2\right\}\\
&\bm{Y}^{k+1}\triangleq \mathop{argmin}\limits_{Y}\left\{\mathcal{L}_{\rho}(\bm{P}^{k},\bm{Y},\bm{U}^k)+\frac{1}{2}\|\bm{Y}-\bm{Y}^k\|_\Psi^2\right\}\label{yupdate}\\
&\bm{U}^{k+1}\triangleq \bm{U}^k-\zeta\rho(\bm{P}^{k+1}-\bm{Y}^{k+1})
\end{align}
\begin{definition}\label{Def_DOC}
{如果选择~$\delta_i>0$~使得参数~$\rho,~\zeta,~\Phi,~\Psi$~满足以下的情况:}
\begin{align*}
\left\{
\begin{array}{cl}
\Phi\succ\rho(\frac{1}{\delta_1}-1)I,\\
\Psi\succ\rho(\frac{1}{\delta_2}-1)I,\\
\delta_1+\delta_2<2-\zeta,
\end{array}\right.
\end{align*}
\end{definition}
选择参数\,$\rho,~\zeta,~\Phi,~\Psi$\,的方法多种多样,~本文采用一个简单的选择\,$\Phi=\phi I,\Psi=\psi I$\,使得
\begin{align*}
\left\{
\begin{array}{cl}
\phi\succ\rho(\frac{1}{\delta_1}-1),\\
\psi\succ\rho(\frac{1}{\delta_2}-1),\\
\delta_1+\delta_2<2-\zeta,
\end{array}\right.
\end{align*}

\section{计算P}
本节给出了在计算\,$\bm{P}$\,的详细信息,\,从指示函数的定义中可以容易地看出,\,$\bm{p}^{k+1}$\,的实际优化策略如下:
\begin{align}
\bm{P}^{k+1}=\mathop{argmin}\limits_{P\in\mathcal{P}^{(1)}}\left\{F(\bm{P})+\frac{\rho}{2}\|\bm{P}-\bm{Y}^k+\bm{U}^k\|_F^2+\frac{\phi}{2}(\bm{P}-\bm{P}^k)^T(\bm{P}-\bm{P}^k)\right\}
\end{align}
当\,$n=N+1$\,时
\begin{align}
\bm{p}_{N+1}^{k+1}=\frac{\rho(\bm{U}_n^k-\bm{y}_{N+1}^k)+\phi\bm{P}_{N+1}^k}{2+\rho+\phi}
\end{align}

对于每一个~n=1,...,N,\,令$$f(\bm{p})\triangleq \sum\limits_{n \in \mathcal{N}}\left\{f_n(p_{nt})-\omega_ng_n(\sum_{t\in \mathcal{T}}p_{nt})+\gamma\|\bm{p}_n\|_1\right\}$$
相应的子问题计算如下
\begin{align}\label{subp}
\bm{p}_n^{k+1}=\mathop{argmin}\limits_{\bm{p}_n\in\mathcal{P}_n^{(1)}}\,\left\{f(\bm{p})+\frac{\rho}{2}\|\bm{p}_n-\bm{y}_n^k+\bm{U}_n^k\|_F^2+\frac{\psi}{2}(\bm{p}_n-\bm{p}_n^k)^T(\bm{p}_n-\bm{p}_n^k)\right\}
\end{align}
\section{计算Y}
本节详细介绍\,(\ref{yupdate})\,中变量\,$\bm{Y}$\,的更新,\,等价于求解以下凸优化问题的解:
\begin{align}\label{subob}
\bm{Y}^{k+1}&=\mathop{argmin}\limits_{\bm{Y}}~\mathcal{I}_2(\bm{Y})+\frac{\rho}{2}\|\bm{P}^k-\bm{Y}+\bm{U}^k\|_F^2+\frac{\psi}{2}\|\bm{Y}-\bm{Y}^k\|_F^2\\
       &=\mathop{argmin}\limits_{\bm{Y}\in\mathcal{P}^{(2)}}~\frac{\rho}{2}\|\bm{Y}-(\bm{P}^{k}+\bm{U}^k)\|_F^2+\frac{\psi}{2}\|\bm{Y}-\bm{Y}^k\|_F^2\nonumber
\end{align}
对于~$\bm{y}-update$~的更新,~可以由以下分散方式计算变量
\begin{align}\label{subbb}
\mathop{min}\limits_{\bm{y}_t\in\mathcal{P}_t^{(2)}}\,\,\left\{(\rho+\psi)\bm{y}_t^T\bm{y}_t-2(\rho(\bm{p}_t^k+\bm{U}_t^k)+\psi\bm{y}_t^k)\bm{y}_t\right\}
\end{align}
子问题(\ref{subbb})是一个CQP问题.\,为了简化符号,~我们引入一个~$(L\times N)$~矩阵~$A^t$~来表示时刻\,$t$\,的馈线用户关联矩阵及其在\,$a_{l,n}^t$\, 处的分量
 \begin{equation}
a_{l,n}^t=\left\{
\begin{array}{cl}
1  &  if~PEV~n~uses~feeder~l~at~time~t \\
0  &  otherwise \\
\end{array} \right.
\end{equation}
设\,$A^t=(a_1^t,...,a_N^t)$\,$a_n^t$\,是\,$A^t$\,的第\,$n$\,列向量,\,表示\,$EV n$\,使用的相应馈线)\,$a_{N+1}^t=0\in \mathcal{R}^l,\,$\,$c^t=(c_{1,t},...c_{l,t})$,\,$b_n -1,n\in\mathcal{N},b_{N+1}=1$,~ 那么子问题重写为
\begin{align}\label{subyone}
&min \quad\sum_{n=1}^{N+1}[(\rho+\psi)y_{n,t}^2-2(\rho(p_{n,t}^k+U_{n,t}^k)+\psi y_{n,t}^k)y_{n,t}]\\
&s.t.\quad\,\,\sum_{n=1}^{N+1}a_n^ty_{n,t}\leq c^t\\
&\quad\quad\,\,\,\,\sum_{n=1}^{N+1}b_ny_{n,t}=d_t\label{subytwo}
\end{align}
引入子问题\,(\ref{subyone})-(\ref{subytwo})\,的拉格朗日函数
\begin{align}\label{dualp}
\mathcal{L}^t(\bm{y}_t;\lambda_t,\mu_t)&=\sum_{n=1}^{N+1}[(\rho+\psi)y_{n,t}^2-2(\rho(p_{n,t}^k+U_{n,t}^k)+\psi y_{n,t}^k)y_{n,t}]\\\nonumber
&+\lambda_t^T[a_n^ty_{n,t}-c^t/(N+1)]+\mu_t[b_ny_{n,t}-d_t/(N+1)]\\
&:=\sum_{n=1}^{N+1}\mathcal{L}_{n=1}^t(y_t;\lambda_t,\mu_t)\nonumber
\end{align}
(\ref{dualp})的对偶问题为
\begin{align}\label{maxobj}
\mathop{max}_{\lambda_t\succeq0,\mu_t}\left\{D^t(\lambda_t,\mu_t)=\sum_{n=1}^{N+1}\mathop{min}_{y_t}\mathcal{L}^t(y_t;\lambda_t,\mu_t)\right\}
\end{align}
根据(\ref{maxobj}),\,目标函数被重写为
\begin{align}
D^t(\lambda_t,\mu_t)=\sum_{n=1}^{N+1}\mathop{min}_{y_{n,t}}\mathcal{L}_n^t(y_t;\lambda_t,\mu_t)
\end{align}
{\color{blue}第二种思路:\\
由于(\ref{subob})中的函数是解耦的,\,因此计算其变量\,$y_t^k$,\,\,t=1,...,T.\,的优化问题为
\begin{align}
&\min_{y_t\in \mathcal{P}_t^{(2)}}\quad[(\rho+\psi)y_t^2-2(\rho(p_i^k+\bm{u}_i^k)+\psi y_i^k)y_t]\\
&\quad s.t.\quad \quad \hat{p}_{nt}^{min}\leq y_t\leq \hat{p}_{nt}^{max}
\end{align}
它的解析解很容易得:
\begin{equation}
y_t^{k+1}=\left\{
\begin{array}{cl}
\hat{p}_{nt}^{min} &  \overline{y}_t^{k+1}<\hat{p}_{nt}^{min} \\
\overline{y}_t^{k+1}  & \hat{p}_{nt}^{min}\leq \overline{y}_t^{k+1}\leq \hat{p}_{nt}^{max} \\
 \hat{p}_{nt}^{max}& \overline{y}_t^{k+1}<\hat{p}_{nt}^{max}\\
\end{array} \right.
\end{equation}}
\section{算法}
算法收敛的表证如下：
\begin{align*}
\bm{r}^{k+1}=\|\bm{P}^{k+1}-\bm{Y}^{k+1}\|_F
\end{align*}
\begin{align*}
\bm{s}^{k+1}=\|\rho(\bm{Y}^{k+1}-\bm{Y}^{k})\|_F
\end{align*}




一个合理的终止标准是原始残差和对偶残差要足够小,~如下:
\begin{align*}
\|\bm{r}^k\|_2\leq \varepsilon^{pri}\,\,\,\,\,\,\,\,\|\bm{s}^k\|_2\leq \varepsilon^{dual}
\end{align*}
where~$\varepsilon^{pri}>0$~和~$\varepsilon^{dual}>0$~are feasibility~tolerances~for~the~primal~and~dual~feasibity~conditions~()~and~().These~tolerances~can~be~
chosen~using~an~absolute~and~relative~criterion,such~as
\begin{align*}
&\varepsilon^{pri}=\sqrt{N}\varepsilon^{abs}+\varepsilon^{rel}max\{\|p\|_2,\|-x\|_2\},\\
&\varepsilon^{dual}=\sqrt{N}\varepsilon^{abs}+\varepsilon^{rel}\|\mu^k\|_2
\end{align*}
where~$\varepsilon^{abs}>0$~is~an~absolute~tolerance~and~$\varepsilon^{rel}>0$~is~a~relative~tolerance.A~reasonable~value~for~the~relative~stopping
criterion~might~be~$10^{-3}$~or~$10^{-4}$.~A~pseudo-code~for~the~proposed Prox-JADMM~is~then~give~in~Algorithm~1.
\begin{algorithm}[!h]
    \caption{Jacobi-Proximal ADMM}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE $\mathbf{p}_n^0(n=1,...,N+1)$,~$\Lambda^0 $
        \ENSURE $\mathbf{p}_n^k(n=1,...,N+1)$    %%output
        \FOR{k=0,1,...}
                \STATE Update~$\mathbf{p}_n$~for~$n=1,...,N+1$~in parallel by:
                \STATE \qquad $\mathbf{p}_n^{k+1}= \textrm{\bl{argmin} }\big\{ f_n(\mathbf{p}_n)
                +\frac{\rho}{2}\|A_n\mathbf{p}_n+\sum\limits_{j\neq n}A_j\mathbf{p}_j^k -c -\frac{\Lambda^k}{\rho}\|_2^2+\frac{1}{2}\|\mathbf{p}_n-\mathbf{p}_n^k\|_{\Psi}^2\big\}$
        \STATE Update $\Lambda$ by:
                \STATE \qquad $\Lambda^{k+1}=\Lambda^k-\gamma\rho(\sum_{n=1}^N A_n\mathbf{p}_n^{k+1}-c)$
        \IF {$\sum_{n=1}^{N+1}\|\mathbf{p}_n^{k+1}-\mathbf{p}_n^{k}\|_F \leq \varepsilon^{pri}$}
            \STATE Break.
        \ENDIF
        \ENDFOR
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[!h]
    \caption{algorithm of JPADMM}
    \label{alg:AOA}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE tolerance error $\epsilon^{pri}$, $\epsilon^{dual}$,
        penalty parameter\,$\rho$\,\\
        \qquad $P^0, Y^0,\,\,\mu^0$ %%input
        \ENSURE $P,Y$    %%output

        \STATE
        \WHILE{$\|P^{k+1}-Y^{k+1}\|_F>\epsilon^{pri}$\,or \,$\|\rho(Y^{k+1}-Y^{k})\|_F>\epsilon^{dual}$\,}
            \STATE P-update:
\STATE ~~for~$n=1,...,N$,\\
\STATE 计算\,$p_n^{k+1}$\,通过\,$\bm{p}_n^{k+1}=\mathop{argmin}\limits_{\bm{p}_n\in\mathcal{P}_n^{(1)}}\,\left\{f(\bm{p})+\frac{\rho}{2}\|\bm{p}_n-\bm{y}_n^k+\bm{U}_n^k\|_F^2+\frac{\psi}{2}(\bm{p}_n-\bm{p}_n^k)^T(\bm{p}_n-\bm{p}_n^k)\right\}$\,
\STATE~~for~$n=N+1$;
\STATE 计算:~$\bm{p}_{N+1}^{k+1}=\frac{\rho(\bm{U}_n^k-\bm{y}_{N+1}^k)+\phi\bm{P}_{N+1}^k}{2+\rho+\phi}$;
%\IF {CP\_new is empty}
\STATE Y-update:\\
\STATE~~for~$t=1,...,T$;\\
\STATE {\color{red}Y的计算根据子算法(算法2)};\\
\STATE $\mu$-update:\\
\STATE ~~for n=1,...,N+1,~t=1,...,T.\\
\STATE $\mu_{n,t}^{k+1}=\mu_{n,t}^k+\gamma\rho(P_{n,t}^{k+1}-Y_{n,t}^{k+1})$\\
\STATE 更新~$r^{k+1}=\|P^{k+1}-Y^{k+1}\|_F$\\
\STATE 更新~$s^{k+1}=\|\rho(Y^{k+1}-Y^{k+1})\|_F$~\\
\STATE 更新~$k:=k+1$
        \ENDWHILE



        \RETURN EEEEE
    \end{algorithmic}
\end{algorithm}


%\begin{algorithm}[htb]
%\caption{ Algorithm Algorithm Algorithm Algorithm}
%\label{alg:Framwork}
%\begin{algorithmic}[] %这个1 表示每一行都显示数字
%\REQUIRE ~~\\ %算法的输入参数：Input
%Initialization:\\
%Set the tolerance error $\epsilon^{pri}$,~$\epsilon^{dual}$,~penalty parameter~$\rho>0$~\\
%Set initial values~$P^0, Y^0,~\mu^0$~\\
%
%\ENSURE ~~\\
%
%%\IF {not the end of current sentence}
%\STATE P-update:
%\STATE ~~for~$n=1,...,N$,\\
%\STATE 计算:~$p_n^{k+1}=\mathop{argmin}\limits_{P\in\mathcal{P}^{(1)}}~G_n(p)+\frac{\rho}{2}\|p_n-y_n+\frac{\mu_n}{\rho}\|_F^2+\frac{\psi}{2}(p_n-p_n^k)^T(p_n-p_n^k)$;
%\STATE~~for~$n=N+1$;
%\STATE 计算:~$p_{N+1}^{k+1}=\frac{\rho}{\rho-2\omega_n}(\frac{\mu_{N+1}^k}{\rho}-y_{N+1}^{k})$;
%%\IF {CP\_new is empty}
%\STATE Y-update:\\
%\STATE~~for~$t=1,...,T$;\\
%\STATE {\color{red}Y的计算根据子算法(算法1)};\\
%\STATE $\mu$-update:\\
%\STATE ~~for n=1,...,N+1,~t=1,...,T.\\
%\STATE $\mu_{n,t}^{k+1}=\mu_{n,t}^k+\gamma\rho(P_{n,t}^{k+1}-Y_{n,t}^{k+1})$\\
%\STATE 更新~$r^{k+1}=\|P^{k+1}-Y^{k+1}\|_F$\\
%\STATE 更新~$s^{k+1}=\|\rho(Y^{k+1}-Y^{k+1})\|_F$~\\
%\STATE 更新~$k:=k+1$
%
%~~判断~$r^{k+1}>\epsilon^{pri}$~或者~$s^{k+1}>\epsilon^{dual}$~
%\end{algorithmic}
%\end{algorithm}



%\section{加速投影梯度}
%\subsection{准备工作}
%稀疏约束优化:
%\begin{align}\tag{1}
%\min_{w\in A_s} f(w),
%\end{align}
%稀疏集:
%\begin{align}\tag{2}
%A_s:=\{w\in\Re^n:\|w\|_0\leq s\},
%\end{align}
%传统的线性回归是最小化最小二乘~$(LS)$~损失函数:
%\begin{align}\tag{3}
%f(w)=\|y=Xw\|^2/2.
%\end{align}
%问题结构:
%\begin{align}\tag{4}
%f(w)=g(Xw),\quad g(z)=\sum_{i=1}^m g_i(z_i),
%\end{align}
%\subsection{梯度投影}
%求解问题~(1)~的梯度投影:
%\begin{align}\tag{5}
%w^{k+1}\in \mathbf{T}_{PG}^{\lambda}(w^k):=P_{A_s}(w^k-\lambda \nabla f(w^k)),
%\end{align}
%~$f$~具有~$L-Lipschitz$~
%\begin{align}\tag{6}
%\|\nabla f(w)-\nabla f(w')\|\leq L\|w-w'\|\quad w,w'\in \Re^n,
%\end{align}
%(2)给出的非凸集可以分解为:
%\begin{align}\tag{7}
%A_s=\bigcup_{J\in\mathbf{J}_s}A_J,\quad A_J:=span{e_j:j\in J},\quad \mathbf{J}_s:=\{J\subseteq\{1,2,...,n\}:|J|=s\},
%\end{align}
%
%
%\textbf{Theorem 2.1}\quad 设~$\{w^k\}$~为~(5)~生成的序列,那么：
%
%(a)(子序列收敛)~$\{f(w_k)\}$~要么是严格递减的,~要么存在~$N>0$,~ 使得对于所有~$k\geq N$,~使得~$w^k=w^N$.~此外,~${w^k}$~ 的任何聚点~$w^*$~ 满足~$w^*\in P_{A_s}(w^*-\lambda \nabla f(w^*))$,~因此是~(1)~的稳定点。
%
%(b)(子空间识别和完全收敛) 存在~$N \in \mathbb{N}$~使得
%\begin{align}\tag{8}
%\{w^k\}_{k=N}^{\infty}\subseteq \bigcup_{J\in \mathbf{I}_{w^*}}A_J,\quad \mathbf{I}_{w^*}:=\{J\in \mathbf{J}_s:w^*\in A_J\}.
%\end{align}
%每当~$w^k\rightarrow w^*$.~特别是,~如果~$\mathbf{T}_ {PG}^{\lambda}(w^*)$~ 是单态的,~${w^k}$~的聚点是~$w^*$,~则~$w^*$~ 是~$(1)$~的局部极小值,$w^k\rightarrow w^*$,~且~(8)~ 成立.
%
%(c)(局部线性收敛) 如果对于聚点~$w^*$,~$\mathbf{T}_ {PG}^{\lambda}(w^*)$~是单态的,~并且对于所有~$J\in \mathbb{I}_{w^*}$,~$w \mapsto w-\lambda \Delta f(w)$~是对~$A_J$~ 的收缩,~ 则~${w^k}$~以~$Q$~线性速率收敛到~$w^*$.~换句话说,~$N_2\in N$~和~$\gamma \in [0,1)$~使得
%\begin{align}\tag{9}
%\|w^{k+1}-w^*\|\leq \gamma \|w^k-w^*\|,\quad \forall k \geq N_2.
%\end{align}
%\textbf{Theorem 2.2}(收敛率)
%\subsection{本文主要贡献}
%
%1、在Bertsimas等[11]的次线性结果的基础上,~我们证明了(1)的PG具有局部线性速率全局收敛到局部最优.~我们强调我们的框架与[11]一样,~ 适用于满足凸性和光滑性要求的一般损失函数,~因此,~ 它不仅涵盖了经典的稀疏回归问题,~还涵盖了经验风险最小化(ERM)框架所包含的许多其他问题.\\
%
%2、{\color{red}通过分解As作为线性子空间的并集,~我们进一步证明了PG能够识别包含局部最优值为(1)的子空间.}~利用这一性质,~我们为一般问题(1)提出了两种具有实际实现和收敛保证的加速策略.~我们的加速为收敛提供了计算和理论上的优势,~特别是可以获得超线性收敛.~\\
%
%3、与现有的非凸问题加速方法相比[27,36],~该工作提供了新的加速方案,~ 具有更快的理论速度(参见定理3.2和3.3),~除了应用于经典的PG算法之外,~ 这些方案还可以很容易地与现有的加速PG 方法结合,~ 进一步使它们收敛得更快.\\
%
%4、数值实验证明了我们的加速方法在迭代和运行时间上的显著改进,~ 特别是优于[11] 的投影梯度算法和[27]提出的求解非凸问题的加速近端梯度方法.
%
%
%\section{加速方法}
%
%这项工作的主要焦点是在本节中提出的具有可靠收敛保证的新技术,~以加速上一节中提出的~$PG$~算法.~我们的技术充分利用包含~(8)~所描述的子空间识别特性,~ 以及~(4)~的问题结构来设计有效的算法.\\
%
%我们强调,~下面描述的两种加速策略是可以结合在一起的,~而且它们也具有广泛的适用性,~只要现有算法具有类似于~(8)~的属性,~它们就可以应用于~(1)~ 的其他算法。
%
%\subsection{外推加速}
%
%传统的外推技术在凸优化领域中发现,~以加速算法【9,30】,~保证收敛性的提高,~但通常只被用作非凸设置的启发式,~直到最近的一些工作表明也可以实现理论收敛【27,36】,~然而,~与凸情况不同的是,~对于非凸问题,~ 这些外推策略不会导致更快的收敛速度,~也没有这样做的直观原因.
%
%外推步骤沿着由两次连续迭代确定的方向选择一个正的步长.~也就是说,~ 给定两次迭代~$w^{k-1}$~和~$w^k$,~当步长~$t_k\geq0$~时,~首先计算中间点~$z^k:=w^k+t^k(w^k-w^{k-1})$~，然后应用原始算法映射(在我们的例子中为~$\mathbf{T}_{PG}^{\lambda}$~)\\
%
%{\color{red}另一个流行的梯度算法加速方案是由【5】开创的谱方法.~} 他们利用连续两次迭代的梯度和迭代的差值来估计当前点的曲率,~并利用它来决定沿梯度相反的方向更新的步长.~在【38】中已经表明,~用回溯过程来装备这个步长可以显著更快地收敛正则化优化问题的近端梯度，这包括我们对(1)的PG作为一个特例.\\
%
%为了描述我们提出的结合外推和谱技术的双加速过程,~我们首先观察到所有~$PG$~迭代都位于~$A_s$~上,~并且~$A_s$~可以被有限分解为(7).~ 对于某些~$J\in\mathbb{J}$~当两个连续迭代位于同一凸子空间~$A_J$~ 上时,~在这两个迭代中,~我们实际上是在进行凸优化.~ 在这种情况下,~$A_J$~内的外推步骤是合理的,~因为它不会违反约束,~并且可以从【9,31】 中关于凸问题的加速近端梯度的改进率中预期加速.~由定理2.1(b)可知,~对应的~$J$~也是一个候选指标集属于~$\mathbb{I}_{w^*}$,~因此在~$A_J$~内进行外推更有意义,~如果~$d^k$~ 不是~$f$~ 在~$w^k$~处的下降方向,~我们设~$t_k=0$~以跳过外推步骤.~ 否则,~我们从由~$f$~ 的曲率信息决定的某个~$\hat{t}_k>0$~ 开始,~然后沿着~$d^k:=w^k-w^{k-1}$~ 进行回溯线搜索,~使~$t_k=\eta^i\hat{t}_k$~为能提供足够下降的最小整数~$i\geq0$\\
%\begin{align}\tag{12}
%f(w^{k}+t_kd^k)\leq f(w^k)-\sigma t_k^2\|d^k\|^2,
%\end{align}
%给定参数~$\eta,\sigma\in(0,1)$,~则应用~(5)~令~$z^k=w^k+t_kd^k$~ 得到~$w^{k+1}$.\\~
%
%用于谱初始化,~用于加速收敛,~而不是直接使用【5,38】方法,~将反向梯度作为更新方向,~我们需要设计一个不同的机制,~因为我们的方向~$d^k$~ 与梯度没有直接关系。在【5】中使用的步长
%\begin{align}\tag{13}
%\alpha_k:=<s^k,s^k>/<s^k,r^k>,\quad s^k:=w^k-w^{k-1},\quad r^k:=\nabla f(w^k)-f(w^{k-1})
%\end{align}
%最终更新~$-\alpha_k\nabla f(w^k)$~实际上是以下子问题的最小值
%\begin{align}\tag{14}
%\min_{d\in {\Re}^n}<\nabla f(w^k),d>+\|d\|^2/(2\alpha_k).
%\end{align}
%
%通过将上述二次问题与下降引理[7，引理5.7]提供的上界对比,~我们可以将~$\alpha_k^{-1}$~视为局部~$Lipschitz$~参数的估计,~该参数可以远小于~$L$,~但仍然保证目标的下降.~ 因此,~我们遵循这个思想,~用这样的曲率估计和下降引理来确定~$\hat{t}_k$~
%\begin{align}\tag{15}
%\hat{t}_k=\mathop{argmin}_{t\geq0}<\nabla f(w^k),td^k>+\|td^k\|^2/(2\alpha_k)\Leftrightarrow \hat{t}_k=-<\alpha_k \nabla f(w^k),d^k>/\|d^k\|^2.
%\end{align}
%(13)的另一种解释是:~$\alpha_k^{-1}$~也可作为~$\nabla^2 f(w^k)$~ 的估计,~(14)中的目标是~$f$~的二阶泰勒展开的低成本近似.~然而,~我们注意到,~ 对于~(4)~ 形式的问题和~$d^k\in A_J$~ 精确的二阶泰勒展开
%\begin{align}\tag{16}
%f(w^k+td^k)\approx f(w^k)+t<\nabla f(w^k),d^k>+t^2<\nabla^2f(w^k)d^k,d^k>/2
%\end{align}
%可以高效计算,~尤其是对于~(4)~和任意~$d^k\in A_J$~令~$Xd^k=X:,$~
%\begin{align}\tag{17}
%\nabla f \left(w^{k}\right)^{\top} d^{k} &=\nabla g\left((X w^{k})\right)^{\top}\left(X_{:, J} d_{J}^{k}\right) \\
%\left\langle\nabla^{2} f\left(w^{k}\right) d^{k}, d^{k}\right\rangle &=\left\langle\left(X_{:, J} d_{J}^{k}\right), \nabla^{2} g\left(\left(X w^{k}\right)\right)\left(X_{:, J} d_{J}^{k}\right)\right\rangle,
%\end{align}
%
%%\textcolor{red}{
%\begin{align}\tag{18}
%  \hat{t}_k \leftarrow P_{[c_k \alpha_{\min},c_k\alpha_{\max}]}  (\hat{t}_k)\\
%  c_k:=\|(\nabla f(w^k))_J\|/(\xi_k\|d^k\|), \xi_k=-\langle d^k,\nabla f(w^k)\rangle / (\|d^k\|\|(\nabla f(w^k))_J\|)\in (0,1].\\
%  (f(w)-f(w^*))^\theta\leq \kappa \|(\nabla f(w))_J\|,\forall w\in A_j\bigcap U
%\end{align}
%%}
%\begin{algorithm}[!h]
%    \caption{经典 ADMM}
%    \label{alg:AOA}
%    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
%    \renewcommand{\algorithmicensure}{\textbf{Output:}}
%    \begin{algorithmic}[1]
%        \REQUIRE $x_i^0$,~$z^0$,~$y^0$ %%input
%        \ENSURE EEEEE    %%output
%      % \FOR{k=0,1,...}
%            %\IF {$C = 0$}
%             \WHILE{$A=B$}
%                \STATE Update~$x,z$ by:
%                \STATE $x_i^{k+1}=arg min_{x}~L_{\rho}(x,z^k,y^k)$\\
%                \STATE $y_i^{k+1}=arg min_{x}~L_{\rho}(x^{k+1},z,y^k)$\\
%                \STATE Update $y^{k+1}=y^k-\rho(Ax^{k+1}+Bz^{k+1}-c)$\\
%            \ENDWHILE
           % \ELSE
%                \STATE DDDDD
           % \ENDIF
        %\ENDFOR


       % \STATE  AAAAA
%        \WHILE{$A=B$}
%            \STATE BBBBB
%        \ENDWHILE
%
%        \FOR{each $i \in [1,10]$}
%            \IF {$C = 0$}
%                \STATE CCCCC
%            \ELSE
%                \STATE DDDDD
%            \ENDIF
%        \ENDFOR

      %  \RETURN EEEEE
%    \end{algorithmic}
%\end{algorithm}









%\begin{algorithm}[!h]
%    \caption{Jacobi-Proximal ADMM}
%    \label{alg:AOA}
%    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
%    \renewcommand{\algorithmicensure}{\textbf{Output:}}
%    \begin{algorithmic}[1]
%        \REQUIRE $x^0(i=1,2,...,N)$,~$\lambda^0$~ %%input
%        \ENSURE EEEEE    %%output
%       \FOR{k=0,1,...}
%            %\IF {$C = 0$}
%                \STATE Update~$x_i$~for~$i=1,...,N$~in parallel by:
%                \STATE $x_i^{k+1}=arg min_{x_i}f(x_i)+\frac{\rho}{2}\|A_ix_i+\sum_{j\neq i}A_jx_j^k-c-\frac{\lambda^k}{\rho}\|_2^2+\frac{1}{2}\|x_i-x_i^k\|_{P_i}^2$
%                \STATE Update $\lambda^{k+1}=\lambda^k-\gamma\rho(\sum_{i=1}^N)A_ix_i^{k+1}-c)$
%           % \ELSE
%%                \STATE DDDDD
%            %\ENDIF
%        \ENDFOR


       % \STATE  AAAAA
%        \WHILE{$A=B$}
%            \STATE BBBBB
%        \ENDWHILE
%
%        \FOR{each $i \in [1,10]$}
%            \IF {$C = 0$}
%                \STATE CCCCC
%            \ELSE
%                \STATE DDDDD
%            \ENDIF
%        \ENDFOR

      %  \RETURN EEEEE
%    \end{algorithmic}
%\end{algorithm}


%两块的经典ADMM算法：
%\begin{align*}\tag{20}
%&P^{k+1} \triangleq \mathop{argmin}\limits_{P}\{\mathcal{L}_{\rho}(P,Y,\mu^k)+\frac{1}{2}\|P-P^k\|_{\Phi}^2\}\\
%&Y^{k+1}\triangleq \mathop{argmin}\limits_{Y}\{\mathcal{L}_{\rho}(P^{k},Y,\mu^k)+\frac{1}{2}\|Y-Y^k\|_\Psi^2\}\\
%&\mu^{k+1}\triangleq \mu^k-\zeta\rho(P^{k+1}-Y^{k+1})
%\end{align*}
%\clearpage

\section{详细求解过程}

\subsection{优化问题}
目标函数：
\begin{align*}
G(\{p_{n,t}\}_{n=1,t=1}^{N,T})&=\sum_{n\in \mathcal{N}}\sum_{t\in \mathcal{T}}E_tp_{nt}\Delta t
+\sum_{n\in \mathcal{N}}(\sum_{t\in \mathcal{T}}p_{n,t}-\Gamma_n)^2
+\sum_{n\in \mathcal{N}}\|\{p_{n,t}\}_{t=1}^{T}\|_0\\
&+\sum_{t\in \mathcal{T}}(\sum_{n\in \mathcal{N}}p_{n,t}-(\sum_{t\in \mathcal{T}}\sum_{n\in \mathcal{N}}p_{n,t}))^2
\end{align*}
其中
\begin{itemize}
  \item $E_t$~为~$t$~时间段的电价;
  \item $\Gamma_n$~为电第$n$辆电动汽车的充电需求;
  \item $\Delta t$~为时间间隔.
\end{itemize}



\subsection{约束条件}

\begin{enumerate}
  \item $0 \leq p_{n,t} \leq p_{\max}, \forall \{n,t\}$ 最大功率约束
  \item $p_{n,t}=0, \{n,t\}\in S_{0}$   电车未到充电站功率为0。
  \item $\sum_{n\in \Pi} p_{n,t} \leq c_l, \forall t$ 馈线约束
  \item $ SOC_{c,n}\leq \sum_{t=1}^T p_{n,t} \leq SOC_{d,n}$ 电量约束
\end{enumerate}
其中
\begin{itemize}
  \item  $\Delta t$~为时间间隔.
\end{itemize}

\subsection{转化为多块ADMM}
\bl{注意到$n$取值往往较大，如果所有车辆的优化函数可以并行运算，将极大提高优化效率。注意到：}
\begin{align*}
G(\{p_{n,t}\}_{n=1,t=1}^{N,T})
&=\sum_{t\in \mathcal{T}}E_tp_{1,t}\Delta t+(\sum_{t\in \mathcal{T}}p_{1,t}-\Gamma_1)^2+\|\{p_{1,t}\}_{t=1}^{T}\|_0\\
&+\cdots\\
&+\sum_{t\in \mathcal{T}}E_tp_{N,t}\Delta t+(\sum_{t\in \mathcal{T}}p_{N,t}-\Gamma_N)^2+\|\{p_{N,t}\}_{t=1}^{T}\|_0\\
&+\sum_{t\in \mathcal{T}}(\sum_{n\in \mathcal{N}}p_{n,t}-(\sum_{t\in \mathcal{T}}\sum_{n\in \mathcal{N}}p_{n,t}))^2
\end{align*}

为了简洁，引入符号：
\begin{align}
  &\mathbf{E}(T\times 1)=\left(
\begin{array}c
    E_1\\
    \vdots\\
    E_t\\
    \vdots\\
    E_T
  \end{array}
  \right),
    \mathbf{p}_n(T\times 1)=\left(
\begin{array}c
    p_{n,1}\\
    \vdots\\
    p_{n,t}\\
    \vdots\\
    p_{n,T}
  \end{array}
  \right),
  \mathbf{p}_{N+1}{(T\times 1)}=\left(
\begin{array}c
    p_{N+1,1}\\
    \vdots\\
    p_{N+1,t}\\
    \vdots\\
    p_{N+1,T}
  \end{array}
  \right)\\
&f_n(\mathbf{p}_n):=\underbrace{\mathbf{E}^T\mathbf{p}_n\Delta t}_{\text{第n辆车的充电成本}}
+\underbrace{(\|\mathbf{p}_n\|_1-\Gamma_n)^2}_{\text{满足充电需求}}
+\underbrace{\|\mathbf{p}_n\|_0}_{\text{充电时间尽可能少}}+\mathbf{I}_{\mathcal{X}_n}(\mathbf{p}_n),\quad \forall 1\leq n\leq N\\
&f_{N+1}(\mathbf{p}_{N+1}):=\underbrace{\|\mathbf{p}_{N+1}-\|\mathbf{p}_{N+1}\|_1/N\|_2^2}_{\text{削峰填谷}}
\end{align}
其中
\begin{itemize}
    \item $p_{N+1,t}:=\sum\limits_{n=1}^N p_{n,t}$.
  \end{itemize}\

则上述问题可以等价表述为：

\begin{align*}
  \textrm{minmize } \quad&f_1(\mathbf{p}_1)+\cdots+f_N(\mathbf{p}_N)+f_{N+1}(\mathbf{p}_{N+1})\\
  \textrm{subject to } \quad&\mathbf{p}_1+\cdots+\mathbf{p}_N-\mathbf{p}_{N+1}=\mathbf{0}
\end{align*}
\subsection{Jacobi-Proximal ADMM算法}

\begin{algorithm}[!h]
    \caption{Jacobi-Proximal ADMM}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE $\mathbf{p}_n^0(n=1,...,N+1)$,~$\Lambda^0 $
        \ENSURE $\mathbf{p}_n^k(n=1,...,N+1)$    %%output
        \FOR{k=0,1,...}
                \STATE Update~$\mathbf{p}_n$~for~$n=1,...,N+1$~in parallel by:
                \STATE \qquad $\mathbf{p}_n^{k+1}= \textrm{\bl{argmin} }\big\{ f_n(\mathbf{p}_n)
                +\frac{\rho}{2}\|A_n\mathbf{p}_n+\sum\limits_{j\neq n}A_j\mathbf{p}_j^k -c -\frac{\Lambda^k}{\rho}\|_2^2+\frac{1}{2}\|\mathbf{p}_n-\mathbf{p}_n^k\|_{\Psi}^2\big\}$
        \STATE Update $\Lambda$ by:
                \STATE \qquad $\Lambda^{k+1}=\Lambda^k\rd{+}\gamma\rho(\sum_{n=1}^N A_n\mathbf{p}_n^{k+1}-c)$
        \IF {$\sum_{n=1}^{N+1}\|\mathbf{p}_n^{k+1}-\mathbf{p}_n^{k}\|_F \leq \varepsilon^{pri}$}
            \STATE Break.
        \ENDIF
        \ENDFOR
    \end{algorithmic}
\end{algorithm}
Here we set
\begin{align}
\begin{array}l
  A_n=1, \forall 1\leq n \leq N\\
  A_{N+1}=-1 \\
  c=0;\\
  \Psi=\psi \mathbf{I}=0.1(N-1)\rho \mathbf{I}\\
  F=\mathbf{I}\\
\end{array}
\end{align}
(这里N为块数,\,矩阵的F范数和向量的2范数一致)
and the initial value
\begin{align}
&\mathbf{p}_n^0 =\mathbf{0},\quad \lambda^0 =0,\quad \varepsilon^{pri}= 10^{-3},\quad \rho =0.01, \quad\gamma=1
\end{align}
\begin{algorithm}[!h]
    \caption{Solve argmin}
    \begin{algorithmic}[1]
                \STATE  $n=1,...,N$:
                \STATE  $\mathbf{p}_n^{k+1}= \textrm{argmin} \big\{ \mathbf{E}^T\mathbf{p}_n\Delta t +(\|\mathbf{p}_n\|_1-\Gamma_n)^2 +\|\mathbf{p}_n\|_1$
                \STATE  \hspace{2cm}$+\frac{\rho}{2}\|\mathbf{p}_n+\sum\limits_{j\neq n, N+1}\mathbf{p}_j^k-\mathbf{p}_{N+1}^k -\frac{\Lambda^k}{\rho}\|_2^2+\frac{\psi}{2}\|\mathbf{p}_n-\mathbf{p}_n^k\|_2^2$\big\}
                \STATE  $\mathbf{p}_{N+1}=$: \textrm{argmin} \big\{$ \|\mathbf{p}_{N+1}-\|\mathbf{p}_{N+1}\|_1/N\|_2^2$
                \STATE  \hspace{2cm}$+\frac{\rho}{2}\|\mathbf{p}_{N+1}+\sum\limits_{j\neq N+1}\mathbf{p}_j^k -\frac{\Lambda^k}{\rho}\|_2^2+\frac{\psi}{2}\|\mathbf{p}_{N+1}-\mathbf{p}_{N+1}^k\|_2^2$\big\}

    \end{algorithmic}
\end{algorithm}
\begin{align}
  &H_1=0;\quad f_1=\mathbf{E}\Delta t\\
  &H_2=2\mathbf{I};\quad f_2=-2\mathbf{e}\Gamma_n\\
  &H_3=0;\quad f_3=\mathbf{e}\\
  &\frac{\rho}{2},\quad  Y= \sum\limits_{j\neq n, N+1}\mathbf{p}_j^k-\mathbf{p}_{N+1}^k -\frac{\Lambda^k}{\rho}\\
  &\frac{\psi}{2},\quad Y= \mathbf{p}_n^k\\
  &\frac{\rho}{2},\quad  Y= \sum\limits_{j\neq N+1}\mathbf{p}_j^k -\frac{\Lambda^k}{\rho}\\
  &\frac{\psi}{2},\quad Y= \mathbf{p}_{N+1}^k
\end{align}

\clearpage


    \begin{align}
   \underbrace{min}_{\mathbf{p}_n\in\mathcal{X}_n}  \quad f_n(\mathbf{p}_n)              +\frac{\rho}{2}\|A_n\mathbf{p}_n+\sum_{j\neq }A_j\mathbf{p}_j^k
                -\frac{\lambda^k}{\rho}\|_2^2
                +\frac{1}{2}\|\mathbf{p}_n-\mathbf{p}_n^k\|_{\Psi}^2
    \end{align}
    where
    \begin{align}
&f_n(\mathbf{p}_n):=\underbrace{\mathbf{E}^T\mathbf{p}_n\Delta t}_{\text{第n辆车的充电成本}}
+\underbrace{(\|\mathbf{p}_n\|_1-\Gamma_n)^2}_{\text{满足充电需求}}
+\underbrace{\|\mathbf{p}_n\|_0}_{\text{充电时间尽可能少}},\quad \forall 1\leq n\leq N\\
&f_{N+1}(\mathbf{p}_{N+1}):=\underbrace{\|\mathbf{p}_{N+1}-\|\mathbf{p}_{N+1}\|_1/N\|_2^2}_{\text{削峰填谷}}
\end{align}

    使用matlab 优化工具箱，求解此带约束的二次优化函数，即可
\begin{algorithm}[!h]
    \caption{Solve argmin}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \REQUIRE $\mathbf{p}_n^k(n=1,2,...,N)$,~$\lambda^k$ %%input
        \ENSURE $\mathbf{p}_n^k(n=1,2,...,N)$    %%output
        \STATE Enter the coefficient matrices:
\STATE \quad H = [1 -1; -1 2];
\STATE \quad f = [-2; -6];
\STATE \quad A = [1 1; -1 2; 2 1];
\STATE \quad b = [2; 2; 3];
\STATE \quad lb = zeros(2,1);
\STATE Call quadprog:
\STATE \quad [x] =  quadprog(H,f,A,b,[],[],lb,[],[],options);
    \end{algorithmic}
\end{algorithm}

馈线约束条件可以添加到 $A$ 矩阵中。

\section{ADMM}
\subsection{传统优化问题}
\begin{eqnarray*}
  &\textrm{minimize} & f(x)\\
  &\textrm{subject to} & Ax=c\\
  && \bl{\hat{A}x \leq \hat{c}}
\end{eqnarray*}
$$\text{Set } L_\rho(x,z,y)=f(x)+y^T(Ax-c)+\bl{\hat{y}^T(\hat{A}x-\hat{c})}+(\rho/2)\|Ax-c\|_2^2.$$
\subsection{ADMM（两块）}
\begin{eqnarray*}
  &\textrm{minimize} & f(x)+g(z)\\
  &\textrm{subject to} & Ax+Bz=c
\end{eqnarray*}
则
\begin{align*}
 L_\rho(x,z,y)&=f(x)+g(z)+y^T(Ax+Bz-c)+(\rho/2)\|Ax+Bz-c\|_2^2\\
 &=f(x)+g(z)+\frac{\rho}{2}\|Ax+Bz-c+\frac{y}{\rho}\|_2^2-\frac{\rho}{2}\|\frac{y}{\rho}\|_2^2
\end{align*}

则两块的经典ADMM算法：
\begin{align*}
&x^{k+1} :=\underset{x}{\textrm{argmin}} L_{\rho}(x,z^k,y^k)\\
&z^{k+1} :=\underset{z}{\textrm{argmin}} L_{\rho}(x^{k+1},z,y^k)\\
&y^{k+1} :=y^k+\rho(Ax^{k+1}+Bz^{k+1}-c).
\end{align*}


通过引入符号$u=\frac{y}{\rho}$可以简化表示
\begin{align*}
&x^{k+1} :=\underset{x}{\textrm{argmin}} \{f(x)+\frac{\rho}{2}\|Ax+Bz^k-c+u^k\|_2^2\}\\
&z^{k+1} :=\underset{z}{\textrm{argmin}} \{g(z)+\frac{\rho}{2}\|Ax^{k+1}+Bz-c+u^k\|_2^2\}\\
&u^{k+1} :=u^k+(Ax^{k+1}+Bz^{k+1}-c).
\end{align*}

\subsection{ADMM（多块）}
\subsubsection{原始问题自然多块推广}
\begin{eqnarray*}
  &\textrm{minimize} & \sum\limits_{n=1}^{N}f_n(x_n)\\
  &\textrm{subject to} & \sum\limits_{n=1}^{N}A_nx_n=c
\end{eqnarray*}
\begin{align*}
 L_\rho(x_1,\cdots,x_N,y)&=\sum\limits_{n=1}^{N}f_n(x_n)+y^T(\sum\limits_{n=1}^{N}A_nx_n-c)+(\rho/2)\|\sum\limits_{n=1}^{N}A_nx_n-c\|_2^2\\
 &=\sum\limits_{n=1}^{N}f_n(x_n)+\frac{\rho}{2}\|\sum\limits_{n=1}^{N}A_nx_n-c+\frac{y}{\rho}\|_2^2-\frac{\rho}{2}\|\frac{y}{\rho}\|_2^2
\end{align*}

则多块的ADMM算法：
\begin{align*}
&x_n^{k+1} :=\underset{x_n}{\textrm{argmin}} L_{\rho}(x_1^k,\cdots,x_n,\cdots,x_N^k,y^k),\quad \forall n=1\cdots N\\
&y^{k+1} :=y^k+\rho(\sum\limits_{n=1}^{N}A_n^{k+1}x_n^{k+1}-c).
\end{align*}
\subsubsection{添加紧邻项}
引入符号$u=\frac{y}{\rho}$ 并添加近邻项
\begin{align*}
&x_n^{k+1} :=\underset{x_n}{\textrm{argmin}}\{ f_n(x_n)+\frac{\rho}{2}\|A_nx_n+\sum\limits_{j\neq n}A_jx_j^k-c+u^k\|_2^2+\bl{(\psi/2)\|x_n-x_n^{k}\|_2^2}\},\quad \forall n=1\cdots N\\
&u^{k+1} :=u^k+(\sum\limits_{n=1}^{N}A_nx_n^{k+1}-c).
\end{align*}
\end{CJK*}
\end{document}



